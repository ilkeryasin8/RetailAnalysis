{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import when, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or get your Spark session\n",
    "spark = SparkSession.builder.appName(\"StringIndexExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stop current SparkSession\n",
    "# spark.stop()\n",
    "\n",
    "# # Restart SparkSession\n",
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession.builder.master(\"local[*]\").appName(\"FixPythonWorker\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"D:\\\\1CS\\\\Bil401\\\\RetailAnalysis\\\\new_cleaned_data.csv\")\n",
    "\n",
    "# List of string columns to index (modify based on your actual use case)\n",
    "string_columns = [\n",
    "    \"Customer_ID\", \"Country\", \"Gender\", \"Customer_Segment\",\n",
    "    \"Product_Category\", \"Product_Brand\", \"Product_Type\",\n",
    "    \"Shipping_Method\", \"Payment_Method\",\"products\", \"Transaction_ID\"\n",
    "]\n",
    "\n",
    "# Create StringIndexer stages for each column\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"keep\")\n",
    "    for col in string_columns\n",
    "]\n",
    "\n",
    "# Create and fit the Pipeline\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "indexed_df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# Show all columns including the indexed ones\n",
    "#indexed_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-------+-------------+------+------------+----------------+----------------------+----------------+----------------------+-----------------+-------------------+------------+------------------+---------------+---------------------+--------------+--------------------+------------------+--------------+--------------+--------------------+\n",
      "|Customer_ID|Customer_ID_index|Country|Country_index|Gender|Gender_index|Customer_Segment|Customer_Segment_index|Product_Category|Product_Category_index|    Product_Brand|Product_Brand_index|Product_Type|Product_Type_index|Shipping_Method|Shipping_Method_index|Payment_Method|Payment_Method_index|          products|products_index|Transaction_ID|Transaction_ID_index|\n",
      "+-----------+-----------------+-------+-------------+------+------------+----------------+----------------------+----------------+----------------------+-----------------+-------------------+------------+------------------+---------------+---------------------+--------------+--------------------+------------------+--------------+--------------+--------------------+\n",
      "|    10000.0|          22362.0|    USA|          0.0|  Male|         0.0|         Regular|                   0.0|      Home Decor|                   4.0|Bed Bath & Beyond|                7.0|     Bedding|              27.0|        Express|                  1.0|   Credit Card|                 0.0|             Quilt|         245.0|        297106|            218625.0|\n",
      "|    10000.0|          22362.0|    USA|          0.0|  Male|         0.0|         Regular|                   0.0|         Grocery|                   1.0|        Coca-Cola|                1.0|       Water|               0.0|       Same-Day|                  0.0|        PayPal|                 3.0|   Sparkling water|          10.0|        231568|            145963.0|\n",
      "|    10000.0|          22362.0|    USA|          0.0|  Male|         0.0|         Regular|                   0.0|        Clothing|                   2.0|             Nike|               11.0|      Shorts|              22.0|       Same-Day|                  0.0|          Cash|                 2.0|      Khaki shorts|         279.0|        145036|             49995.0|\n",
      "|    10000.0|          22362.0|    USA|          0.0|  Male|         0.0|         Regular|                   0.0|     Electronics|                   0.0|          Samsung|                2.0|      Tablet|               9.0|        Express|                  1.0|    Debit Card|                 1.0|Amazon Fire Tablet|         111.0|        289810|            210534.0|\n",
      "|    10001.0|          11310.0|     UK|          1.0|  Male|         0.0|         Regular|                   0.0|        Clothing|                   2.0|             Zara|                3.0|       Shirt|              18.0|       Same-Day|                  0.0|          Cash|                 2.0|          Tank top|         182.0|        112295|             13653.0|\n",
      "+-----------+-----------------+-------+-------------+------+------------+----------------+----------------------+----------------+----------------------+-----------------+-------------------+------------+------------------+---------------+---------------------+--------------+--------------------+------------------+--------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a list of columns to display:\n",
    "# Start with \"Customer_ID\", then for each column, add the original and its indexed version.\n",
    "columns_to_show = [col for s in string_columns for col in (s, s + \"_index\")]\n",
    "\n",
    "# Display the first 20 rows of the selected columns.\n",
    "indexed_df.select(*columns_to_show).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User feature headers: ['Country_encoded', 'Age', 'Income', 'Gender_encoded', 'Customer_Segment_encoded']\n",
      "+-----------------+---------------------------------------+\n",
      "|Customer_ID_index|user_features                          |\n",
      "+-----------------+---------------------------------------+\n",
      "|0.0              |(12,[1,5,6,8,9],[1.0,46.0,1.7,1.0,1.0])|\n",
      "|1.0              |(12,[0,5,6,7,9],[1.0,22.0,2.2,1.0,1.0])|\n",
      "|7.0              |(12,[1,5,6,7,9],[1.0,20.0,2.1,1.0,1.0])|\n",
      "|8.0              |(12,[3,5,6,8,9],[1.0,20.0,2.0,1.0,1.0])|\n",
      "|18.0             |(12,[2,5,6,7,9],[1.0,46.0,2.1,1.0,1.0])|\n",
      "+-----------------+---------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 1. User Feature Profiles (user_features_df)\n",
    "# =====================================================\n",
    "\n",
    "# Group by user to extract user-specific attributes\n",
    "user_df = indexed_df.groupBy(\"Customer_ID_index\").agg(\n",
    "    F.first(\"Country\").alias(\"Country\"),\n",
    "    F.first(F.col(\"Age\").cast(\"double\")).alias(\"Age\"),\n",
    "    F.first(F.col(\"Income\").cast(\"double\")).alias(\"Income\"),\n",
    "    F.first(\"Gender\").alias(\"Gender\"),\n",
    "    F.first(\"Customer_Segment\").alias(\"Customer_Segment\")\n",
    ")\n",
    "\n",
    "# Define transformations for categorical user attributes.\n",
    "# For Country:\n",
    "country_indexer = StringIndexer(inputCol=\"Country\", outputCol=\"Country_index\", handleInvalid=\"keep\")\n",
    "country_encoder = OneHotEncoder(inputCol=\"Country_index\", outputCol=\"Country_encoded\")\n",
    "\n",
    "# Define transformations for categorical user attributes.\n",
    "# For Gender:\n",
    "gender_indexer = StringIndexer(inputCol=\"Gender\", outputCol=\"Gender_index\", handleInvalid=\"keep\")\n",
    "gender_encoder = OneHotEncoder(inputCol=\"Gender_index\", outputCol=\"Gender_encoded\")\n",
    "\n",
    "# For Customer_Segment:\n",
    "segment_indexer = StringIndexer(inputCol=\"Customer_Segment\", outputCol=\"Customer_Segment_index\", handleInvalid=\"keep\")\n",
    "segment_encoder = OneHotEncoder(inputCol=\"Customer_Segment_index\", outputCol=\"Customer_Segment_encoded\")\n",
    "\n",
    "# Assemble all user features into a single vector.\n",
    "user_assembler = VectorAssembler(\n",
    "    inputCols=[\"Country_encoded\",\"Age\", \"Income\", \"Gender_encoded\", \"Customer_Segment_encoded\"],\n",
    "    outputCol=\"user_features\"\n",
    ")\n",
    "\n",
    "# Build and apply the pipeline for user features.\n",
    "user_pipeline = Pipeline(stages=[country_indexer, country_encoder, gender_indexer, gender_encoder, segment_indexer, segment_encoder, user_assembler])\n",
    "user_model = user_pipeline.fit(user_df)\n",
    "user_features_df = user_model.transform(user_df)\n",
    "\n",
    "print(\"User feature headers:\", user_assembler.getInputCols())\n",
    "# Show a sample of user features.\n",
    "user_features_df.select(\"Customer_ID_index\", \"user_features\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item feature headers: ['Product_Category_encoded', 'Product_Brand_encoded', 'Product_Type_encoded']\n",
      "+--------------+----------------------------+\n",
      "|products_index|item_features               |\n",
      "+--------------+----------------------------+\n",
      "|0.0           |(57,[3,18,52],[1.0,1.0,1.0])|\n",
      "|1.0           |(57,[4,13,31],[1.0,1.0,1.0])|\n",
      "|2.0           |(57,[3,17,52],[1.0,1.0,1.0])|\n",
      "|3.0           |(57,[3,17,52],[1.0,1.0,1.0])|\n",
      "|4.0           |(57,[3,17,52],[1.0,1.0,1.0])|\n",
      "+--------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =====================================================\n",
    "# 2. Generate Item Feature Profiles (item_features_df)\n",
    "# =====================================================\n",
    "\n",
    "# Group by item to extract item-specific attributes.\n",
    "item_df = indexed_df.groupBy(\"products_index\").agg(\n",
    "    F.first(\"Product_Category\").alias(\"Product_Category\"),\n",
    "    F.first(\"Product_Brand\").alias(\"Product_Brand\"),\n",
    "    F.first(\"Product_Type\").alias(\"Product_Type\")\n",
    ")\n",
    "\n",
    "# Define transformations for categorical item attributes.\n",
    "# For Product_Category:\n",
    "cat_indexer = StringIndexer(inputCol=\"Product_Category\", outputCol=\"Product_Category_index\", handleInvalid=\"keep\")\n",
    "cat_encoder = OneHotEncoder(inputCol=\"Product_Category_index\", outputCol=\"Product_Category_encoded\")\n",
    "\n",
    "# For Product_Brand:\n",
    "brand_indexer = StringIndexer(inputCol=\"Product_Brand\", outputCol=\"Product_Brand_index\", handleInvalid=\"keep\")\n",
    "brand_encoder = OneHotEncoder(inputCol=\"Product_Brand_index\", outputCol=\"Product_Brand_encoded\")\n",
    "\n",
    "# For Product_Type:\n",
    "type_indexer = StringIndexer(inputCol=\"Product_Type\", outputCol=\"Product_Type_index\", handleInvalid=\"keep\")\n",
    "type_encoder = OneHotEncoder(inputCol=\"Product_Type_index\", outputCol=\"Product_Type_encoded\")\n",
    "\n",
    "# Assemble all item features into a single vector.\n",
    "item_assembler = VectorAssembler(\n",
    "    inputCols=[\"Product_Category_encoded\", \"Product_Brand_encoded\", \"Product_Type_encoded\"],\n",
    "    outputCol=\"item_features\"\n",
    ")\n",
    "\n",
    "# Build and apply the pipeline for item features.\n",
    "item_pipeline = Pipeline(stages=[cat_indexer, cat_encoder, brand_indexer, brand_encoder, type_indexer, type_encoder, item_assembler])\n",
    "item_model = item_pipeline.fit(item_df)\n",
    "item_features_df = item_model.transform(item_df)\n",
    "\n",
    "print(\"Item feature headers:\", item_assembler.getInputCols())\n",
    "# Show a sample of item features.\n",
    "item_features_df.select(\"products_index\", \"item_features\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+---+------+------+----------------+------+-------+---------------+----------------+-----------------+------------+---------+---------------+--------------+-------+------------------+--------------+-----------------+-------------+------------+----------------------+----------------------+-------------------+------------------+---------------------+--------------------+--------------+--------------------+---------------+\n",
      "|Customer_ID|Country|Age|Gender|Income|Customer_Segment|  Year|  Month|Total_Purchases|Product_Category|    Product_Brand|Product_Type| Feedback|Shipping_Method|Payment_Method|Ratings|          products|Transaction_ID|Customer_ID_index|Country_index|Gender_index|Customer_Segment_index|Product_Category_index|Product_Brand_index|Product_Type_index|Shipping_Method_index|Payment_Method_index|products_index|Transaction_ID_index|feedback_rating|\n",
      "+-----------+-------+---+------+------+----------------+------+-------+---------------+----------------+-----------------+------------+---------+---------------+--------------+-------+------------------+--------------+-----------------+-------------+------------+----------------------+----------------------+-------------------+------------------+---------------------+--------------------+--------------+--------------------+---------------+\n",
      "|    10000.0|    USA| 26|  Male|   1.8|         Regular|2023.0|   July|            3.0|      Home Decor|Bed Bath & Beyond|     Bedding|     Good|        Express|   Credit Card|    4.0|             Quilt|        297106|          22362.0|          0.0|         0.0|                   0.0|                   4.0|                7.0|              27.0|                  1.0|                 0.0|         245.0|            218625.0|            3.0|\n",
      "|    10000.0|    USA| 26|  Male|   1.8|         Regular|2023.0|    May|            7.0|         Grocery|        Coca-Cola|       Water|Excellent|       Same-Day|        PayPal|    5.0|   Sparkling water|        231568|          22362.0|          0.0|         0.0|                   0.0|                   1.0|                1.0|               0.0|                  0.0|                 3.0|          10.0|            145963.0|            4.0|\n",
      "|    10000.0|    USA| 26|  Male|   1.8|         Regular|2023.0|January|            5.0|        Clothing|             Nike|      Shorts|     Good|       Same-Day|          Cash|    3.0|      Khaki shorts|        145036|          22362.0|          0.0|         0.0|                   0.0|                   2.0|               11.0|              22.0|                  0.0|                 2.0|         279.0|             49995.0|            3.0|\n",
      "|    10000.0|    USA| 26|  Male|   1.8|         Regular|2023.0|   July|            6.0|     Electronics|          Samsung|      Tablet|  Average|        Express|    Debit Card|    2.0|Amazon Fire Tablet|        289810|          22362.0|          0.0|         0.0|                   0.0|                   0.0|                2.0|               9.0|                  1.0|                 1.0|         111.0|            210534.0|            2.0|\n",
      "|    10001.0|     UK| 46|  Male|   1.8|         Regular|2023.0|October|            8.0|        Clothing|             Zara|       Shirt|Excellent|       Same-Day|          Cash|    5.0|          Tank top|        112295|          11310.0|          1.0|         0.0|                   0.0|                   2.0|                3.0|              18.0|                  0.0|                 2.0|         182.0|             13653.0|            4.0|\n",
      "+-----------+-------+---+------+------+----------------+------+-------+---------------+----------------+-----------------+------------+---------+---------------+--------------+-------+------------------+--------------+-----------------+-------------+------------+----------------------+----------------------+-------------------+------------------+---------------------+--------------------+--------------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Transform feedback and rating to integer values\n",
    "indexed_df = indexed_df.withColumn(\n",
    "    \"feedback_rating\",\n",
    "    when(col(\"feedback\") == \"Bad\", 1.0)\n",
    "    .when(col(\"feedback\") == \"Average\", 2.0)\n",
    "    .when(col(\"feedback\") == \"Good\", 3.0)\n",
    "    .when(col(\"feedback\") == \"Excellent\", 4.0)\n",
    "    .otherwise(None)\n",
    ")\n",
    "\n",
    "# Cast Ratings column to Double\n",
    "indexed_df = indexed_df.withColumn(\"Ratings\", col(\"Ratings\").cast(\"Double\"))\n",
    "indexed_df = indexed_df.withColumn(\"Age\", col(\"Age\").cast(\"Int\"))\n",
    "indexed_df = indexed_df.withColumn(\"Income\", col(\"Income\").cast(\"Double\"))\n",
    "indexed_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+---------------+\n",
      "|Ratings|Feedback_rating|Combined_Rating|\n",
      "+-------+---------------+---------------+\n",
      "|    4.0|            3.0|            3.5|\n",
      "|    5.0|            4.0|            4.5|\n",
      "|    3.0|            3.0|            3.0|\n",
      "|    2.0|            2.0|            2.0|\n",
      "|    5.0|            4.0|            4.5|\n",
      "+-------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Weight parameter\n",
    "alpha = 0.5\n",
    "\n",
    "# Create a new column \"Combined_Rating\" as a weighted average of Ratings and Feedback_rating.\n",
    "indexed_df = indexed_df.withColumn(\n",
    "    \"Combined_Rating\",\n",
    "    alpha * col(\"Ratings\") + (1 - alpha) * col(\"Feedback_rating\")\n",
    ")\n",
    "\n",
    "indexed_df.select(\"Ratings\", \"Feedback_rating\", \"Combined_Rating\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Income', 'Ratings', 'Customer_ID_index', 'Country_index', 'Gender_index', 'Customer_Segment_index', 'Product_Category_index', 'Product_Brand_index', 'Product_Type_index', 'Shipping_Method_index', 'Payment_Method_index', 'products_index', 'Transaction_ID_index', 'feedback_rating', 'Combined_Rating']\n"
     ]
    }
   ],
   "source": [
    "#CLEANING\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Get all string-type columns\n",
    "string_cols = [f.name for f in indexed_df.schema.fields if isinstance(f.dataType, StringType)]\n",
    "\n",
    "# Add 'Customer_ID' to the list of columns to drop\n",
    "cols_to_drop = string_cols + ['Customer_ID']\n",
    "\n",
    "# Drop them\n",
    "indexed_df = indexed_df.drop(*cols_to_drop)\n",
    "\n",
    "# Show remaining columns\n",
    "print(indexed_df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate Recommendations with Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------------------------------------------------------------------------------+\n",
      "|Customer_ID_index|recommendations                                                                          |\n",
      "+-----------------+-----------------------------------------------------------------------------------------+\n",
      "|31               |[{114, 3.365354}, {185, 3.232731}, {119, 3.0735805}, {107, 3.0631726}, {68, 3.0317197}]  |\n",
      "|34               |[{156, 2.8354557}, {227, 2.6421156}, {233, 2.4985762}, {280, 2.4845135}, {44, 2.4782188}]|\n",
      "|53               |[{23, 3.0790992}, {241, 2.598433}, {267, 2.5407896}, {282, 2.4733748}, {225, 2.3913903}] |\n",
      "|65               |[{133, 3.3341796}, {301, 3.1203952}, {306, 3.0393007}, {286, 2.950754}, {196, 2.8867276}]|\n",
      "|78               |[{110, 3.6403105}, {301, 3.5453634}, {25, 3.432964}, {290, 3.330237}, {138, 3.3069453}]  |\n",
      "+-----------------+-----------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Split the data into training (80%) and test (20%) sets.\n",
    "# The seed parameter ensures reproducibility.\n",
    "train, test = indexed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Initialize the ALS (Alternating Least Squares) model.\n",
    "# This model is used for collaborative filtering based on user-item interactions.\n",
    "als = ALS(\n",
    "    userCol=\"Customer_ID_index\",   # The numeric user ID column.\n",
    "    itemCol=\"products_index\",      # The numeric item (product) ID column.\n",
    "    ratingCol=\"Ratings_index\",     # The column containing the ratings.\n",
    "    rank=10,                       # The number of latent factors to use.\n",
    "    maxIter=10,                    # The maximum number of iterations to run.\n",
    "    regParam=0.1,                  # The regularization parameter to prevent overfitting.\n",
    "    coldStartStrategy=\"drop\"       # Drop any rows in the test set that result in NaN predictions.\n",
    ")\n",
    "\n",
    "# Fit the ALS model using the training data.\n",
    "model = als.fit(train)\n",
    "\n",
    "# Use the trained model to generate predictions on the test data.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Generate the top 5 product recommendations for each user.\n",
    "# The output DataFrame includes each user (using their numeric ID)\n",
    "# and an array of the top 5 recommendations (each with an item ID and a predicted rating).\n",
    "userRecs = model.recommendForAllUsers(5)\n",
    "\n",
    "# Display the first 5 rows of the recommendations DataFrame without truncating the output.\n",
    "userRecs.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error of 1 (RMSE): 1.8949615546580254\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance using Root Mean Squared Error (RMSE).\n",
    "# RMSE provides a measure of how far off the predictions are from the actual ratings.\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",            # Metric to evaluate the predictions.\n",
    "    labelCol=\"Ratings_index\",     # The true ratings.\n",
    "    predictionCol=\"prediction\"    # The predicted ratings from the model.\n",
    ")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error of 1 (RMSE):\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate Recommendation with of Feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------------------------------------------------------------------------------+\n",
      "|Customer_ID_index|recommendations                                                                          |\n",
      "+-----------------+-----------------------------------------------------------------------------------------+\n",
      "|31               |[{317, 4.0936956}, {181, 4.0158234}, {121, 4.008103}, {140, 3.9531443}, {104, 3.9278402}]|\n",
      "|34               |[{127, 3.9885442}, {47, 3.8163028}, {172, 3.7226963}, {299, 3.7008548}, {232, 3.6916926}]|\n",
      "|53               |[{124, 3.7288048}, {125, 3.6961417}, {317, 3.574184}, {12, 3.5740798}, {5, 3.560285}]    |\n",
      "|65               |[{121, 3.7714088}, {124, 3.714796}, {1, 3.7112274}, {109, 3.7063365}, {147, 3.491488}]   |\n",
      "|78               |[{317, 4.4578514}, {124, 4.2468185}, {128, 3.9579995}, {121, 3.941046}, {127, 3.8532882}]|\n",
      "+-----------------+-----------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training (80%) and test (20%) sets for the feedback model.\n",
    "train_fb, test_fb = indexed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Initialize the ALS model using the feedback-based rating column.\n",
    "als_fb = ALS(\n",
    "    userCol=\"Customer_ID_index\",   # User identifier (numeric)\n",
    "    itemCol=\"products_index\",      # Item identifier (numeric)\n",
    "    ratingCol=\"feedback_rating\",   # Use the numeric feedback as the rating signal\n",
    "    rank=10,                       # Number of latent factors\n",
    "    maxIter=10,                    # Number of iterations\n",
    "    regParam=0.1,                  # Regularization parameter\n",
    "    coldStartStrategy=\"drop\"       # Drop NaN predictions during evaluation\n",
    ")\n",
    "\n",
    "# Train the ALS model on the full indexed dataset.\n",
    "als_model_fb = als_fb.fit(indexed_df)\n",
    "\n",
    "# Generate top 5 recommendations for every user.\n",
    "userRecs = als_model_fb.recommendForAllUsers(5)\n",
    "\n",
    "# Display a sample of the ALS recommendations.\n",
    "userRecs.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error of Feedback model (RMSE): 0.3324427998719281\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on the test set.\n",
    "predictions_fb = als_model_fb.transform(test_fb)\n",
    "\n",
    "# Evaluate the model's performance using Root Mean Squared Error (RMSE).\n",
    "# RMSE provides a measure of how far off the predictions are from the actual ratings.\n",
    "evaluator_fb = RegressionEvaluator(\n",
    "    metricName=\"rmse\",            # Metric to evaluate the predictions.\n",
    "    labelCol=\"feedback_rating\",     # The true ratings.\n",
    "    predictionCol=\"prediction\"    # The predicted ratings from the model.\n",
    ")\n",
    "rmse = evaluator_fb.evaluate(predictions_fb)\n",
    "print(\"Root-mean-square error of Feedback model (RMSE):\", rmse)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
