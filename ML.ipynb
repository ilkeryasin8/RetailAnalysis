{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or get your Spark session\n",
    "spark = SparkSession.builder.appName(\"StringIndexExample\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"D:\\\\1CS\\\\Bil401\\\\RetailAnalysis\\\\new_cleaned_data.csv\")\n",
    "\n",
    "# List of string columns to index (modify based on your actual use case)\n",
    "string_columns = [\n",
    "    \"Customer_ID\", \"Country\", \"Gender\", \"Customer_Segment\",\n",
    "    \"Product_Category\", \"Product_Brand\", \"Product_Type\", \"Feedback\",\n",
    "    \"Shipping_Method\", \"Payment_Method\", \"Ratings\",\"products\"\n",
    "]\n",
    "\n",
    "# Create StringIndexer stages for each column\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=col, outputCol=col + \"_index\", handleInvalid=\"keep\")\n",
    "    for col in string_columns\n",
    "]\n",
    "\n",
    "# Create and fit the Pipeline\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "indexed_df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# Show all columns including the indexed ones\n",
    "#indexed_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------------+-------+-------------+------+------------+----------------+----------------------+----------------+----------------------+-----------------+-------------------+------------+------------------+---------+--------------+---------------+---------------------+--------------+--------------------+-------+-------------+------------------+--------------+\n",
      "|Customer_ID|Customer_ID|Customer_ID_index|Country|Country_index|Gender|Gender_index|Customer_Segment|Customer_Segment_index|Product_Category|Product_Category_index|    Product_Brand|Product_Brand_index|Product_Type|Product_Type_index| Feedback|Feedback_index|Shipping_Method|Shipping_Method_index|Payment_Method|Payment_Method_index|Ratings|Ratings_index|          products|products_index|\n",
      "+-----------+-----------+-----------------+-------+-------------+------+------------+----------------+----------------------+----------------+----------------------+-----------------+-------------------+------------+------------------+---------+--------------+---------------+---------------------+--------------+--------------------+-------+-------------+------------------+--------------+\n",
      "|    10000.0|    10000.0|          22362.0|    USA|          0.0|  Male|         0.0|         Regular|                   0.0|      Home Decor|                   4.0|Bed Bath & Beyond|                7.0|     Bedding|              27.0|     Good|           1.0|        Express|                  1.0|   Credit Card|                 0.0|    4.0|          0.0|             Quilt|         245.0|\n",
      "|    10000.0|    10000.0|          22362.0|    USA|          0.0|  Male|         0.0|         Regular|                   0.0|         Grocery|                   1.0|        Coca-Cola|                1.0|       Water|               0.0|Excellent|           0.0|       Same-Day|                  0.0|        PayPal|                 3.0|    5.0|          2.0|   Sparkling water|          10.0|\n",
      "|    10000.0|    10000.0|          22362.0|    USA|          0.0|  Male|         0.0|         Regular|                   0.0|        Clothing|                   2.0|             Nike|               11.0|      Shorts|              22.0|     Good|           1.0|       Same-Day|                  0.0|          Cash|                 2.0|    3.0|          3.0|      Khaki shorts|         279.0|\n",
      "|    10000.0|    10000.0|          22362.0|    USA|          0.0|  Male|         0.0|         Regular|                   0.0|     Electronics|                   0.0|          Samsung|                2.0|      Tablet|               9.0|  Average|           2.0|        Express|                  1.0|    Debit Card|                 1.0|    2.0|          1.0|Amazon Fire Tablet|         111.0|\n",
      "|    10001.0|    10001.0|          11310.0|     UK|          1.0|  Male|         0.0|         Regular|                   0.0|        Clothing|                   2.0|             Zara|                3.0|       Shirt|              18.0|Excellent|           0.0|       Same-Day|                  0.0|          Cash|                 2.0|    5.0|          2.0|          Tank top|         182.0|\n",
      "+-----------+-----------+-----------------+-------+-------------+------+------------+----------------+----------------------+----------------+----------------------+-----------------+-------------------+------------+------------------+---------+--------------+---------------+---------------------+--------------+--------------------+-------+-------------+------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a list of columns to display:\n",
    "# Start with \"Customer_ID\", then for each column, add the original and its indexed version.\n",
    "columns_to_show = [\"Customer_ID\"] + [col for s in string_columns for col in (s, s + \"_index\")]\n",
    "\n",
    "# Display the first 20 rows of the selected columns.\n",
    "indexed_df.select(*columns_to_show).show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error (RMSE): 1.8949615546580254\n",
      "+-----------------+-----------------------------------------------------------------------------------------+\n",
      "|Customer_ID_index|recommendations                                                                          |\n",
      "+-----------------+-----------------------------------------------------------------------------------------+\n",
      "|31               |[{114, 3.365354}, {185, 3.232731}, {119, 3.0735805}, {107, 3.0631726}, {68, 3.0317197}]  |\n",
      "|34               |[{156, 2.8354557}, {227, 2.6421156}, {233, 2.4985762}, {280, 2.4845135}, {44, 2.4782188}]|\n",
      "|53               |[{23, 3.0790992}, {241, 2.598433}, {267, 2.5407896}, {282, 2.4733748}, {225, 2.3913903}] |\n",
      "|65               |[{133, 3.3341796}, {301, 3.1203952}, {306, 3.0393007}, {286, 2.950754}, {196, 2.8867276}]|\n",
      "|78               |[{110, 3.6403105}, {301, 3.5453634}, {25, 3.432964}, {290, 3.330237}, {138, 3.3069453}]  |\n",
      "+-----------------+-----------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Cast the Ratings column to float (if not already numeric)\n",
    "indexed_df = indexed_df.withColumn(\"Ratings_index\", indexed_df[\"Ratings_index\"])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train, test = indexed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Initialize the ALS model\n",
    "als = ALS(\n",
    "    userCol=\"Customer_ID_index\",   # User identifier (numeric)\n",
    "    itemCol=\"products_index\",      # Item identifier (numeric)\n",
    "    ratingCol=\"Ratings_index\",           # Rating column\n",
    "    rank=10,                       # Number of latent factors\n",
    "    maxIter=10,                    # Number of iterations\n",
    "    regParam=0.1,                  # Regularization parameter\n",
    "    coldStartStrategy=\"drop\"       # Drop NaN predictions during evaluation\n",
    ")\n",
    "\n",
    "# Fit the model on the training data\n",
    "model = als.fit(train)\n",
    "\n",
    "# Generate predictions on the test set\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Evaluate the model using Root Mean Squared Error (RMSE)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Ratings_index\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error (RMSE):\", rmse)\n",
    "\n",
    "# Generate top 5 product recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(5)\n",
    "userRecs.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
